{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021cd6f-55e8-49ab-8a83-57d2098c8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625fc78-4989-477d-9aa0-29232a650496",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac2290-225d-4b1b-a9a4-fac64d95967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c62ca5-8381-4bcb-9276-daf001fb44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5613446-8cda-4b00-aea4-4aba0dda9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ed718-277a-44e3-816b-5d8c7be2b56f",
   "metadata": {},
   "source": [
    "# В данном проекте, мы напишем простенький парсер неденамического сайта, при этом мы создадим csv файл и заодно json файл для каждого продукта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b1845ba-fd43-435f-948d-9e4bfa3e76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from time import sleep \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c4bf5e-84a0-40e9-b1a1-7df5caca7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://health-diet.ru/table_calorie/?utm_source=leftMenu&utm_medium=table_calorie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "323c0113-1dc5-4bf9-ad7f-6af1cbfec29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чуть-чуть шифруемся и делаем вид, что мы не бот).\n",
    "headers = {\n",
    "    \"Accept\": \"**************************\",\n",
    "    \"Accept-Encoding\" : \"**************************\",\n",
    "    \"Accept-Language\" : \"**************************\",\n",
    "    \"User-Agent\" : \"**************************\"\n",
    "}\n",
    "# Можно еще добавить куки, но я в целях безопасности убрал их, чтобы залить этот проект на git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d838882-f79e-4598-b40d-85802f824342",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(url, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da578463-7898-4ad1-83f8-4a2a82e8f6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Тут проверяем что ответ полученный от сервера 200, если так, то все супер, можно работать \n",
    "print(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa946bd7-882b-4d0f-9dbf-ab51362367a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = req.text\n",
    "# Копируем себе сайт, чтобы спокойно с ним работать\n",
    "with open(\"index.html\", \"w\", encoding = 'utf-8') as file: \n",
    "    file.write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f7cf8-642c-4fb9-95b3-a0f7dc275e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a6bba95-b46f-4199-b149-02cb4a87c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"index.html\", encoding = 'utf-8') as file:\n",
    "    scr = file.read()\n",
    "\n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "all_products_class = soup.find_all(class_ = 'mzr-tc-group-item-href')\n",
    "\n",
    "all_categories = {}\n",
    "for item in all_products_class:\n",
    "    item_category = item.text\n",
    "    item_link = \"https://health-diet.ru\" + item.get(\"href\")\n",
    "\n",
    "    all_categories[item_category] = item_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb63119a-99c9-4587-9b54-c66befa1350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, name in all_categories.items():\n",
    "    print(f\"{index} {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce5542-8e6a-4066-aadc-bbd26bdb85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_categories.json\", encoding = 'utf-8') as file:\n",
    "    all_categories = json.load(file)\n",
    "\n",
    "iteration_cnt = int(len(all_categories)) - 1\n",
    "count = 0\n",
    "print(f'Всего итераций {iteration_cnt}')\n",
    "for category, category_link in all_categories.items():\n",
    "    rep = [',', ' ', '-', \"`\", \"'\"]\n",
    "    for item in rep:\n",
    "        if item in category:\n",
    "            category = category.replace(item, \"_\")\n",
    "\n",
    "    req = requests.get(url = category_link, headers = headers)\n",
    "    src = req.text\n",
    "\n",
    "    with open(f\"data/{count}_{category}.html\", \"w\", encoding= \"utf-8\") as file:\n",
    "        file.write(src)\n",
    "\n",
    "    with open(f\"data/{count}_{category}.html\", encoding= \"utf-8\") as file:\n",
    "        src = file.read()\n",
    "\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "\n",
    "    alert_block = soup.find(class_ = \"uk-alert-danger\")\n",
    "    if alert_block is not None:\n",
    "        continue\n",
    "    \n",
    "    table_head = soup.find(class_='mzr-tc-group-table').find(\"tr\").find_all(\"th\")\n",
    "    product = table_head[0].text\n",
    "    calories = table_head[1].text\n",
    "    proteins = table_head[2].text\n",
    "    fats = table_head[3].text\n",
    "    carbohydrates = table_head[4].text\n",
    "\n",
    "    with open(f\"data/{count}_{category}.csv\", \"w\", encoding = \"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            product,\n",
    "            calories,\n",
    "            proteins,\n",
    "            fats,\n",
    "            carbohydrates\n",
    "        ])\n",
    "\n",
    "    products_data = soup.find(class_ = \"mzr-tc-group-table\").find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "    product_info = []\n",
    "    for item in products_data:\n",
    "        product_tds = item.find_all(\"td\")\n",
    "\n",
    "        title = product_tds[0].find(\"a\").text\n",
    "        calories = product_tds[1].text\n",
    "        proteins = product_tds[2].text\n",
    "        fats = product_tds[3].text\n",
    "        carbohydrate = product_tds[4].text\n",
    "\n",
    "        product_info.append(\n",
    "            {\n",
    "                \"title\" : title,\n",
    "                \"calories\" : calories,\n",
    "                \"protein\" : proteins,\n",
    "                \"fats\" : fats,\n",
    "                \"carbohydrate\" : carbohydrate\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        with open(f\"data/{count}_{category}.csv\", \"a\", encoding = \"utf-8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                title,\n",
    "                calories,\n",
    "                proteins,\n",
    "                fats,\n",
    "                carbohydrates\n",
    "            ])\n",
    "\n",
    "    with open(f'data/{count}_{category}.json', \"a\", encoding = \"utf-8\") as file:\n",
    "        json.dump(product_info, file, indent = 4, ensure_ascii=False)\n",
    "        \n",
    "    count += 1\n",
    "    print(f\"Итерация {count}. {category} записан...\")\n",
    "    iteration_cnt -= 1\n",
    "\n",
    "    if iteration_cnt == 0:\n",
    "        print(f'Усе, работа off')\n",
    "        break\n",
    "        \n",
    "    print(f'Осталось {iteration_cnt} итераций')\n",
    "    sleep(random.randrange(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90af538b-ccd6-41c4-a9c0-e010925a5ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Теперь у нас на компе создалась папка data/Название каждой категории и в "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b468f76-203f-4e5c-b791-a1164aeec95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
